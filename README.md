# Sistema de Agentes Inteligentes en Rust

**Un laboratorio de desarrollo para explorar sistemas distribuidos, agentes de IA y la eficiencia de Rust.**

[![Estado de la Construcci√≥n](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/usuario/repositorio)
[![Licencia](https://img.shields.io/badge/license-MIT-blue)](https://opensource.org/licenses/MIT)
[![Rust](https://img.shields.io/badge/rust-1.79%2B-orange)](https://www.rust-lang.org/)
[![NATS](https://img.shields.io/badge/comms-NATS-blueviolet)](https://nats.io/)

Este repositorio documenta el desarrollo de un sistema distribuido y extensible construido en Rust. Utiliza una arquitectura multi-agente para procesar, analizar y resumir archivos, sirviendo como un entorno pr√°ctico para la investigaci√≥n y aplicaci√≥n de tecnolog√≠as avanzadas.

El sistema se fundamenta en una comunicaci√≥n as√≠ncrona a trav√©s de un bus de mensajer√≠a NATS y se integra con m√∫ltiples proveedores de Modelos de Lenguaje Grandes (LLM) a trav√©s de un **Gateway** unificado, demostrando un enfoque modular y agn√≥stico a la tecnolog√≠a.

## üî≠ Visi√≥n del Proyecto

Este proyecto es m√°s que una simple aplicaci√≥n; es un campo de pruebas dise√±ado para profundizar en varias √°reas clave de la ingenier√≠a de software moderna:

*   **Dominio de Rust:** Aprovechar la seguridad, concurrencia y rendimiento de Rust para construir servicios de bajo nivel robustos y eficientes.
*   **Sistemas Distribuidos:** Dise√±ar y operar una arquitectura descentralizada, enfrentando desaf√≠os como la comunicaci√≥n entre servicios, la tolerancia a fallos y la escalabilidad.
*   **Agentes de Inteligencia Artificial:** Implementar un sistema multi-agente donde entidades aut√≥nomas colaboran para resolver tareas complejas, sentando las bases para aplicaciones de IA m√°s sofisticadas.
*   **Integraci√≥n de LLMs:** Abstraer la comunicaci√≥n con diversos proveedores de LLM (Ollama, OpenAI, Groq), desarrollando una pasarela flexible que centraliza la l√≥gica y facilita la extensibilidad.
*   **Protocolos de Comunicaci√≥n Eficientes:** Dise√±ar e implementar un protocolo de comunicaci√≥n personalizado (MCP) para estandarizar y optimizar el intercambio de datos entre los agentes y los sistemas de IA.

## üöÄ Caracter√≠sticas Principales

*   **Arquitectura Multi-Agente:** Cada responsabilidad (exploraci√≥n de archivos, extracci√≥n de metadatos, resumen) es encapsulada en un agente independiente y aut√≥nomo.
*   **Comunicaci√≥n As√≠ncrona y Desacoplada:** El uso de NATS como bus de mensajer√≠a garantiza la resiliencia y escalabilidad del sistema, permitiendo que los agentes operen de forma independiente.
*   **LLM Gateway Unificado:** Act√∫a como un proxy inteligente que abstrae la complejidad de interactuar con diferentes APIs de LLMs, permitiendo el enrutamiento y la configuraci√≥n centralizada.
*   **Cliente Interactivo de Escritorio:** Una GUI construida con `egui` que sirve como centro de mando para interactuar con el ecosistema de agentes y visualizar resultados en tiempo real.
*   **Orquestador de Agentes:** Un lanzador centralizado (`agent_launcher`) que gestiona el ciclo de vida de todos los agentes del sistema, aplicando pol√≠ticas de reinicio para garantizar la alta disponibilidad.
*   **Configuraci√≥n Declarativa:** El comportamiento del sistema se define a trav√©s de un archivo `config.toml` y variables de entorno, facilitando la personalizaci√≥n y el despliegue.

## üèóÔ∏è Arquitectura del Sistema

La arquitectura est√° dise√±ada siguiendo los principios de los sistemas distribuidos, priorizando el **desacoplamiento**, la **resiliencia** y la **escalabilidad horizontal**. Cada componente es un proceso independiente que se comunica exclusivamente a trav√©s del bus de mensajer√≠a, lo que permite que puedan ser desplegados, actualizados y reiniciados de forma aislada.

1.  **NATS Server**: Act√∫a como el sistema nervioso central, gestionando todos los flujos de comunicaci√≥n.
2.  **Agent Launcher**: Punto de entrada del backend. Orquesta el lanzamiento y la supervisi√≥n de los agentes seg√∫n la configuraci√≥n definida.
3.  **Agentes de Backend**:
    *   `file_explorer`: Escanea directorios locales y expone el contenido de los archivos bajo demanda.
    *   `metadata_extractor`: Extrae y sirve metadatos estructurados de los archivos.
    *   `summarizer`: Orquesta el flujo de resumen, coordinando con otros agentes para obtener datos y con el LLM Gateway para generar el resultado.
    *   `llm_gateway`: Recibe solicitudes de procesamiento de lenguaje natural y las delega al proveedor de LLM configurado, gestionando la autenticaci√≥n y adaptaci√≥n de la API.
4.  **Cliente Interactivo**: La interfaz de usuario final que se conecta a NATS para enviar comandos y recibir actualizaciones de manera as√≠ncrona.

![Diagrama de Arquitectura (Conceptual)](https://i.imgur.com/example.png)
*(Nota: Reemplaza esta imagen con un diagrama de tu arquitectura detallado).*

## üí° Protocolo de Comunicaci√≥n (MCP)

Para garantizar una comunicaci√≥n eficiente y estandarizada entre el `summarizer` y el `llm_gateway`, se ha dise√±ado un Protocolo de Comunicaci√≥n de Modelos (MCP, *Model Communication Protocol*).

*   **Prop√≥sito**: Define una estructura de mensajes agn√≥stica al proveedor final de LLM, permitiendo que los agentes soliciten tareas de IA sin necesidad de conocer los detalles de implementaci√≥n de OpenAI, Groq u otros.
*   **Implementaci√≥n**: La especificaci√≥n y las estructuras de datos de este protocolo se encuentran en `src/mcp_protocol.rs`.

## üõ†Ô∏è Componentes

El proyecto se estructura en los siguientes binarios ejecutables:

| Binario | Archivo Fuente | Descripci√≥n |
|---|---|---|
| `agent_launcher` | `src/bin/6_agent_launcher.rs` | **Orquestador principal.** Lanza y supervisa a los dem√°s agentes. |
| `file_explorer` | `src/bin/1_file_explorer.rs` | Agente que escanea el sistema de archivos y sirve el contenido. |
| `metadata_extractor` | `src/bin/2_metadata_extractor.rs` | Agente que extrae y devuelve metadatos de un archivo. |
| `summarizer` | `src/bin/3_summarizer.rs` | Agente que orquesta la l√≥gica de resumen y se comunica con el LLM Gateway. |
| `llm_gateway` | `src/bin/5_llm_gateway.rs` | **Puerta de enlace a LLMs.** Gestiona la comunicaci√≥n con proveedores externos. |
| `interactive_client` | `src/bin/4_interactive_client.rs` | **GUI de escritorio.** Permite al usuario interactuar con el sistema. |

## ‚öôÔ∏è Requisitos Previos

*   **Rust**: Toolchain de Rust (`rustc` y `cargo`). Inst√°lalo desde [rustup.rs](https://rustup.rs/).
*   **Docker**: Para ejecutar el servidor NATS de forma aislada.
*   **(Opcional) Ollama**: Si deseas utilizar modelos de lenguaje de forma local. Aseg√∫rate de tener un modelo descargado (ej: `ollama pull llama3.1:8b`).

## üöÄ Gu√≠a de Inicio R√°pido

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu_usuario/tu_repositorio.git
cd tu_repositorio
```

### 2. Configurar el Entorno

Crea un archivo `.env` a partir de un `env.example` (buena pr√°ctica) o desde cero en la ra√≠z del proyecto.

```dotenv
# .env

# URL del servidor NATS.
NATS_URL="nats://127.0.0.1:4222"

# Directorio que el explorador de archivos escanear√°.
DIRECTORY_TO_SCAN="/ruta/absoluta/a/tus/documentos"

# Configuraci√≥n para el LLM Gateway
SUMMARIZER_MODEL="ollama:llama3.1:8b" # Formato: proveedor:nombre-del-modelo
LLM_PROVIDER="ollama"                 # Proveedor por defecto: auto | ollama | openai | groq

# (Opcional) Claves de API para servicios remotos
OPENAI_API_KEY="sk-..."
GROQ_API_KEY="gsk_..."
```

### 3. Iniciar NATS Server

Usa Docker para lanzar una instancia de NATS de forma r√°pida y limpia.

```bash
docker run --rm -p 4222:4222 -p 8222:8222 --name nats-server nats:latest
```

### 4. Iniciar los Agentes de Backend

En una terminal, ejecuta el `agent_launcher`. Este compilar√° y ejecutar√° todos los agentes habilitados en `config.toml`.

```bash
cargo run --bin agent_launcher
```

### 5. Iniciar el Cliente Interactivo

En una **segunda terminal**, lanza la interfaz gr√°fica.

```bash
cargo run --bin interactive_client```

¬°Listo! La GUI se conectar√° al ecosistema de agentes a trav√©s de NATS, permiti√©ndote explorar archivos y solicitar res√∫menes.

## üîß Configuraci√≥n Avanzada

### `config.toml`

Este archivo es el manifiesto para el `agent_launcher`.

*   `build_profile`: Perfil de compilaci√≥n (`debug` o `release`).
*   `[[agents]]`: Lista de agentes a gestionar.
    *   `name`: Nombre descriptivo para logs.
    *   `bin`: Nombre del binario ejecutable.
    *   `enabled`: `true` para iniciarlo, `false` para ignorarlo.
    *   `restart`: Pol√≠tica de reinicio (`never`, `on_failure`, `always`).

## üå± Desarrollo y Futuras Mejoras

Este proyecto est√° en constante evoluci√≥n. Algunas de las √°reas de inter√©s para el futuro desarrollo incluyen:

*   **A√±adir Nuevos Agentes:** Crear agentes para tareas como extracci√≥n de entidades (NER), an√°lisis de sentimiento o clasificaci√≥n de documentos.
*   **Soporte para m√°s Proveedores de LLM:** Integrar nuevos proveedores en el `llm_gateway` como Anthropic (Claude) o Cohere.
*   **Persistencia de Datos:** Implementar un agente de base de datos para almacenar y consultar los resultados de los an√°lisis.
*   **Containerizaci√≥n Completa:** Escribir un archivo `docker-compose.yml` para levantar todo el ecosistema (NATS y todos los agentes) con un solo comando.
*   **Seguridad y Autenticaci√≥n:** Implementar mecanismos de seguridad en NATS para proteger la comunicaci√≥n entre agentes.

Las contribuciones y sugerencias son siempre bienvenidas.

## üìÑ Licencia

Este proyecto est√° distribuido bajo la Licencia MIT. Consulta el archivo `LICENSE` para m√°s detalles.